{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "\n",
    "from torch import nn\n",
    "from transformers import RobertaTokenizer, RobertaModel, RobertaConfig\n",
    "from transformers import DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from transformers import AdamW\n",
    "from torch.utils.data import Dataset as TorchDataset\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_dataset, Dataset\n",
    "from typing import List, Dict\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, Tuple\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 加载数据\n",
    "with open('all_bug_report.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 转换数据为 DataFrame\n",
    "bug_report = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>nonbug/bug</th>\n",
       "      <th>root cause</th>\n",
       "      <th>impact</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>bug</td>\n",
       "      <td>semantic</td>\n",
       "      <td>unk</td>\n",
       "      <td>Comparison operators</td>\n",
       "      <td>The front end doesn t understand etc. Hilariou...</td>\n",
       "      <td>I got lost somewhere inside semantic checking ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>nonbug</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>porting the examples in python using the provi...</td>\n",
       "      <td>As in the title do you have any plan to provid...</td>\n",
       "      <td>Hi mscipio thank you for the query. We will pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>bug</td>\n",
       "      <td>document</td>\n",
       "      <td>warning style error</td>\n",
       "      <td>in Start example typo</td>\n",
       "      <td>in Docs Let s start with a simple example is a...</td>\n",
       "      <td>in docs source introduction.rst not fix yet.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>invalid</td>\n",
       "      <td>cannot reproduce</td>\n",
       "      <td></td>\n",
       "      <td>Determine whether a loop should be parallelize...</td>\n",
       "      <td>ISL internally dictates if loops should be run...</td>\n",
       "      <td>can you add some description for this wsmoses ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>bug</td>\n",
       "      <td>document</td>\n",
       "      <td>operation failure</td>\n",
       "      <td>Investigate install TC instructions in docker</td>\n",
       "      <td>there are permission denied issues with git cl...</td>\n",
       "      <td>fixed by 33 \\n \\nasking users to do ssh keys s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID nonbug/bug        root cause               impact  \\\n",
       "0  16        bug          semantic                  unk   \n",
       "1  22     nonbug                                          \n",
       "2  29        bug          document  warning style error   \n",
       "3  34    invalid  cannot reproduce                        \n",
       "4  35        bug          document    operation failure   \n",
       "\n",
       "                                               title  \\\n",
       "0                               Comparison operators   \n",
       "1  porting the examples in python using the provi...   \n",
       "2                              in Start example typo   \n",
       "3  Determine whether a loop should be parallelize...   \n",
       "4      Investigate install TC instructions in docker   \n",
       "\n",
       "                                             summary  \\\n",
       "0  The front end doesn t understand etc. Hilariou...   \n",
       "1  As in the title do you have any plan to provid...   \n",
       "2  in Docs Let s start with a simple example is a...   \n",
       "3  ISL internally dictates if loops should be run...   \n",
       "4  there are permission denied issues with git cl...   \n",
       "\n",
       "                                            comments  \n",
       "0  I got lost somewhere inside semantic checking ...  \n",
       "1  Hi mscipio thank you for the query. We will pr...  \n",
       "2     in docs source introduction.rst not fix yet.\\n  \n",
       "3  can you add some description for this wsmoses ...  \n",
       "4  fixed by 33 \\n \\nasking users to do ssh keys s...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bug_report.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "root cause\n",
       "semantic           488\n",
       "question           227\n",
       "enhancement        116\n",
       "feature request    105\n",
       "compatibility       78\n",
       "document            60\n",
       "new function        60\n",
       "environment         36\n",
       "memory              14\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bug_report['nonbug/bug'] = bug_report['nonbug/bug'].fillna('invalid')\n",
    "keep_causes = [\n",
    "    'semantic', 'question', 'enhancement', 'feature request', 'compatibility', 'document',\n",
    "    'new function', 'environment', 'memory'\n",
    "]\n",
    "# 使用 apply 方法检查并设置 NaN\n",
    "bug_report['root cause'] = bug_report['root cause'].apply(lambda x: x if x in keep_causes else np.nan)\n",
    "keep_causes = [\n",
    "    'semantic', 'question', 'enhancement', 'feature request', 'compatibility', 'document',\n",
    "    'new function', 'environment', 'memory'\n",
    "]\n",
    "\n",
    "# 使用 apply 方法检查并设置 NaN\n",
    "bug_report['root cause'] = bug_report['root cause'].apply(lambda x: x if x in keep_causes else np.nan)\n",
    "bug_report['root cause'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "impact\n",
       "crash/exception            308\n",
       "build/compilation error    108\n",
       "others                      82\n",
       "wrong output                79\n",
       "warning style error         73\n",
       "operation failure           34\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep_impacts = [\n",
    "    'crash/exception','build/compilation error','wrong output',\n",
    "    'operation failure','warning style error'\n",
    "]\n",
    "bug_report['impact'] = bug_report['impact'].replace({\n",
    "    'build error': 'build/compilation error',\n",
    "    'compilation error': 'build/compilation error', \n",
    "    'build/compilation failure':'build/compilation error',\n",
    "    'warningstyleerror': 'warning style error',\n",
    "    'warningstylerrot': 'warning style error'  ,\n",
    "    'operationfailure': 'operation failure',\n",
    "    'wrongoutput': 'wrong output',\n",
    "})\n",
    "bug_report['impact'] = bug_report['impact'].apply(lambda x: np.nan if x == '' else (x if x in keep_impacts else 'others'))\n",
    "bug_report['impact'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>comments</th>\n",
       "      <th>impact_build/compilation error</th>\n",
       "      <th>impact_crash/exception</th>\n",
       "      <th>impact_operation failure</th>\n",
       "      <th>impact_others</th>\n",
       "      <th>impact_warning style error</th>\n",
       "      <th>impact_wrong output</th>\n",
       "      <th>...</th>\n",
       "      <th>root cause_memory</th>\n",
       "      <th>root cause_new function</th>\n",
       "      <th>root cause_question</th>\n",
       "      <th>root cause_semantic</th>\n",
       "      <th>root cause_nan</th>\n",
       "      <th>nonbug/bug_bug</th>\n",
       "      <th>nonbug/bug_invalid</th>\n",
       "      <th>nonbug/bug_nonbug</th>\n",
       "      <th>nonbug/bug_nan</th>\n",
       "      <th>merged_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>Comparison operators</td>\n",
       "      <td>The front end doesn t understand etc. Hilariou...</td>\n",
       "      <td>I got lost somewhere inside semantic checking ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Comparison operators The front end doesn t und...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>porting the examples in python using the provi...</td>\n",
       "      <td>As in the title do you have any plan to provid...</td>\n",
       "      <td>Hi mscipio thank you for the query. We will pr...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>porting the examples in python using the provi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>in Start example typo</td>\n",
       "      <td>in Docs Let s start with a simple example is a...</td>\n",
       "      <td>in docs source introduction.rst not fix yet.\\n</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>in Start example typo in Docs Let s start with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>Determine whether a loop should be parallelize...</td>\n",
       "      <td>ISL internally dictates if loops should be run...</td>\n",
       "      <td>can you add some description for this wsmoses ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Determine whether a loop should be parallelize...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>Investigate install TC instructions in docker</td>\n",
       "      <td>there are permission denied issues with git cl...</td>\n",
       "      <td>fixed by 33 \\n \\nasking users to do ssh keys s...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Investigate install TC instructions in docker ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                              title  \\\n",
       "0  16                               Comparison operators   \n",
       "1  22  porting the examples in python using the provi...   \n",
       "2  29                              in Start example typo   \n",
       "3  34  Determine whether a loop should be parallelize...   \n",
       "4  35      Investigate install TC instructions in docker   \n",
       "\n",
       "                                             summary  \\\n",
       "0  The front end doesn t understand etc. Hilariou...   \n",
       "1  As in the title do you have any plan to provid...   \n",
       "2  in Docs Let s start with a simple example is a...   \n",
       "3  ISL internally dictates if loops should be run...   \n",
       "4  there are permission denied issues with git cl...   \n",
       "\n",
       "                                            comments  \\\n",
       "0  I got lost somewhere inside semantic checking ...   \n",
       "1  Hi mscipio thank you for the query. We will pr...   \n",
       "2     in docs source introduction.rst not fix yet.\\n   \n",
       "3  can you add some description for this wsmoses ...   \n",
       "4  fixed by 33 \\n \\nasking users to do ssh keys s...   \n",
       "\n",
       "   impact_build/compilation error  impact_crash/exception  \\\n",
       "0                           False                   False   \n",
       "1                           False                   False   \n",
       "2                           False                   False   \n",
       "3                           False                   False   \n",
       "4                           False                   False   \n",
       "\n",
       "   impact_operation failure  impact_others  impact_warning style error  \\\n",
       "0                     False           True                       False   \n",
       "1                     False          False                       False   \n",
       "2                     False          False                        True   \n",
       "3                     False          False                       False   \n",
       "4                      True          False                       False   \n",
       "\n",
       "   impact_wrong output  ...  root cause_memory  root cause_new function  \\\n",
       "0                False  ...              False                    False   \n",
       "1                False  ...              False                    False   \n",
       "2                False  ...              False                    False   \n",
       "3                False  ...              False                    False   \n",
       "4                False  ...              False                    False   \n",
       "\n",
       "   root cause_question  root cause_semantic  root cause_nan  nonbug/bug_bug  \\\n",
       "0                False                 True           False            True   \n",
       "1                False                False            True           False   \n",
       "2                False                False           False            True   \n",
       "3                False                False            True           False   \n",
       "4                False                False           False            True   \n",
       "\n",
       "   nonbug/bug_invalid  nonbug/bug_nonbug  nonbug/bug_nan  \\\n",
       "0               False              False           False   \n",
       "1               False               True           False   \n",
       "2               False              False           False   \n",
       "3                True              False           False   \n",
       "4               False              False           False   \n",
       "\n",
       "                                         merged_text  \n",
       "0  Comparison operators The front end doesn t und...  \n",
       "1  porting the examples in python using the provi...  \n",
       "2  in Start example typo in Docs Let s start with...  \n",
       "3  Determine whether a loop should be parallelize...  \n",
       "4  Investigate install TC instructions in docker ...  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bug_report= pd.get_dummies(bug_report, columns=['impact', 'root cause', 'nonbug/bug'], dummy_na=True)\n",
    "bug_report['merged_text'] = bug_report['title'] + \" \" + bug_report['summary']  \n",
    "bug_report.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "e:\\python\\Lib\\site-packages\\transformers\\optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8 - Average Loss: 5.6267\n",
      "Epoch 2/8 - Average Loss: 3.8556\n",
      "Epoch 3/8 - Average Loss: 3.3625\n",
      "Epoch 4/8 - Average Loss: 2.9597\n",
      "Epoch 5/8 - Average Loss: 2.7481\n",
      "Epoch 6/8 - Average Loss: 2.6038\n",
      "Epoch 7/8 - Average Loss: 2.4849\n",
      "Epoch 8/8 - Average Loss: 2.4415\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "global_model = None\n",
    "global_tokenizer = None\n",
    "\n",
    "#加载高频掩码词\n",
    "def load_professional_vocab(json_path):\n",
    "    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "        vocab = json.load(f)\n",
    "    # Assuming vocab is a list of words\n",
    "    return set(vocab)\n",
    "\n",
    "# 自定义分词器\n",
    "class BugReportDataset(Dataset):\n",
    "    def __init__(self, dataframe: pd.DataFrame, tokenizer: RobertaTokenizer,\n",
    "                 max_length: int, professional_vocab: set, mask_prob=0.15):\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.professional_vocab = professional_vocab\n",
    "        self.mask_prob = mask_prob\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def mask_tokens(self, inputs: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "\n",
    "\n",
    "        labels = inputs.clone()\n",
    "        probability_matrix = torch.full(labels.shape, self.mask_prob)\n",
    "    \n",
    "        # 获取专业词汇的 token 索引\n",
    "        vocab_indices = []\n",
    "        for word in self.professional_vocab:\n",
    "            token = self.tokenizer.convert_tokens_to_ids(word)\n",
    "            if token is not None:\n",
    "                vocab_indices.append(token)\n",
    "        if vocab_indices:\n",
    "            mask_indices = torch.zeros(labels.shape, dtype=torch.bool)\n",
    "            for idx in vocab_indices:\n",
    "                mask_indices = mask_indices | (labels == idx)\n",
    "            # 增加专业词汇的掩码概率\n",
    "            probability_matrix = torch.where(mask_indices, 0.5, probability_matrix)\n",
    "        \n",
    "        # 不掩码特殊 token\n",
    "        special_tokens_mask = self.tokenizer.get_special_tokens_mask(labels.tolist(), already_has_special_tokens=True)\n",
    "        special_tokens_mask = torch.tensor(special_tokens_mask, dtype=torch.bool)\n",
    "        probability_matrix.masked_fill_(special_tokens_mask, value=0.0)\n",
    "        \n",
    "        masked_indices = torch.bernoulli(probability_matrix).bool()\n",
    "        labels[~masked_indices] = -100  # 仅对掩码的 token 计算损失\n",
    "\n",
    "      \n",
    "        indices_replaced = torch.bernoulli(torch.full(labels.shape, 0.8)).bool() & masked_indices\n",
    "        inputs[indices_replaced] = self.tokenizer.convert_tokens_to_ids(self.tokenizer.mask_token)\n",
    "        indices_random = torch.bernoulli(torch.full(labels.shape, 0.5)).bool() & masked_indices & ~indices_replaced\n",
    "        random_tokens = torch.randint(len(self.tokenizer), labels.shape, dtype=torch.long)\n",
    "        inputs[indices_random] = random_tokens[indices_random]\n",
    "\n",
    "        return inputs, labels\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        title = row['merged_text']\n",
    "        comments = row['comments']\n",
    "\n",
    "       \n",
    "        title_enc = self.tokenizer(title,\n",
    "                                   truncation=True,\n",
    "                                   padding='max_length',\n",
    "                                   max_length=self.max_length,\n",
    "                                   return_tensors='pt')\n",
    "    \n",
    "        comments_enc = self.tokenizer(comments,\n",
    "                                      truncation=True,\n",
    "                                      padding='max_length',\n",
    "                                      max_length=self.max_length,\n",
    "                                      return_tensors='pt')\n",
    "        \n",
    "    \n",
    "        title_input_ids, title_labels = self.mask_tokens(title_enc['input_ids'].squeeze())\n",
    "        comments_input_ids, comments_labels = self.mask_tokens(comments_enc['input_ids'].squeeze())\n",
    "\n",
    "        return {\n",
    "            'title_input_ids': title_input_ids,\n",
    "            'title_attention_mask': title_enc['attention_mask'].squeeze(),\n",
    "            'title_labels': title_labels,\n",
    "            'comments_input_ids': comments_input_ids,\n",
    "            'comments_attention_mask': comments_enc['attention_mask'].squeeze(),\n",
    "            'comments_labels': comments_labels\n",
    "        }\n",
    "\n",
    "\n",
    "class RobertaForMLMAndContrastive(nn.Module):\n",
    "    def __init__(self, model_name='roberta-base', temperature=0.07):\n",
    "        super(RobertaForMLMAndContrastive, self).__init__()\n",
    "        self.roberta = RobertaModel.from_pretrained(model_name)\n",
    "        self.mlm_head = RobertaMLMHead(self.roberta.config)  # 已修改\n",
    "        self.temperature = temperature\n",
    "        self.cosine_similarity = nn.CosineSimilarity(dim=-1)\n",
    "\n",
    "    def forward(self, title_input_ids, title_attention_mask, title_labels,\n",
    "                comments_input_ids, comments_attention_mask, comments_labels):\n",
    "       \n",
    "        title_outputs = self.roberta(input_ids=title_input_ids, attention_mask=title_attention_mask)\n",
    "        title_hidden_states = title_outputs.last_hidden_state\n",
    "        title_mlm_logits = self.mlm_head(title_hidden_states)\n",
    "\n",
    "        \n",
    "        comments_outputs = self.roberta(input_ids=comments_input_ids, attention_mask=comments_attention_mask)\n",
    "        comments_hidden_states = comments_outputs.last_hidden_state\n",
    "        comments_mlm_logits = self.mlm_head(comments_hidden_states)\n",
    "\n",
    "        \n",
    "        loss_fct = nn.CrossEntropyLoss()\n",
    "        title_mlm_loss = loss_fct(title_mlm_logits.view(-1, self.roberta.config.vocab_size),\n",
    "                                  title_labels.view(-1))\n",
    "        comments_mlm_loss = loss_fct(comments_mlm_logits.view(-1, self.roberta.config.vocab_size),\n",
    "                                     comments_labels.view(-1))\n",
    "        mlm_loss = (title_mlm_loss + comments_mlm_loss) / 2\n",
    "\n",
    "       \n",
    "        title_cls = title_hidden_states[:, 0, :]  # (batch_size, hidden_size)\n",
    "        comments_cls = comments_hidden_states[:, 0, :]  # (batch_size, hidden_size)\n",
    "\n",
    "        \n",
    "        title_norm = title_cls / title_cls.norm(dim=1)[:, None]\n",
    "        comments_norm = comments_cls / comments_cls.norm(dim=1)[:, None]\n",
    "\n",
    "      \n",
    "        similarity_matrix = torch.matmul(title_norm, comments_norm.T) / self.temperature\n",
    "        batch_size = title_input_ids.size(0)\n",
    "        labels = torch.arange(batch_size).to(title_input_ids.device)\n",
    "\n",
    "        contrastive_loss_fct = nn.CrossEntropyLoss()\n",
    "        contrastive_loss_title = contrastive_loss_fct(similarity_matrix, labels)\n",
    "        contrastive_loss_comments = contrastive_loss_fct(similarity_matrix.T, labels)\n",
    "        contrastive_loss = (contrastive_loss_title + contrastive_loss_comments) / 2\n",
    "\n",
    "        \n",
    "        total_loss = (mlm_loss + contrastive_loss) / 2\n",
    "\n",
    "        return total_loss, mlm_loss, contrastive_loss\n",
    "\n",
    "class RobertaMLMHead(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(RobertaMLMHead, self).__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.activation = nn.GELU()\n",
    "        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
    "        self.decoder = nn.Linear(config.hidden_size, config.vocab_size, bias=True)  \n",
    "\n",
    "       \n",
    "        self.decoder.bias.data.zero_()  \n",
    "        self.decoder.weight = self.decoder.weight  \n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        x = self.dense(hidden_states)\n",
    "        x = self.activation(x)\n",
    "        x = self.LayerNorm(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def train(model, dataloader, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        loss, mlm_loss, contrastive_loss = model(\n",
    "            title_input_ids=batch['title_input_ids'],\n",
    "            title_attention_mask=batch['title_attention_mask'],\n",
    "            title_labels=batch['title_labels'],\n",
    "            comments_input_ids=batch['comments_input_ids'],\n",
    "            comments_attention_mask=batch['comments_attention_mask'],\n",
    "            comments_labels=batch['comments_labels']\n",
    "        )\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    return avg_loss\n",
    "\n",
    "def main():\n",
    "    #一些设置 超参数 高频词 分词器\n",
    "    MODEL_NAME = 'roberta-base'\n",
    "    MAX_LENGTH = 128\n",
    "    BATCH_SIZE = 16\n",
    "    EPOCHS = 8\n",
    "    LEARNING_RATE = 5e-5\n",
    "    PROFESSIONAL_VOCAB_JSON = 'frequent_words.json'  \n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    tokenizer = RobertaTokenizer.from_pretrained(MODEL_NAME)\n",
    "    professional_vocab = load_professional_vocab(PROFESSIONAL_VOCAB_JSON)\n",
    "\n",
    "    #数据加载\n",
    "    dataset = BugReportDataset(bug_report, tokenizer, MAX_LENGTH, professional_vocab)\n",
    "    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    # 模型\n",
    "    model = RobertaForMLMAndContrastive(model_name=MODEL_NAME)\n",
    "    model.to(device)\n",
    "    optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "    total_steps = len(dataloader) * EPOCHS\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                                num_warmup_steps=int(0.1 * total_steps),\n",
    "                                                num_training_steps=total_steps)\n",
    "\n",
    "    # 训练\n",
    "    for epoch in range(EPOCHS):\n",
    "        avg_loss = train(model, dataloader, optimizer, scheduler, device)\n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS} - Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "    torch.save(model.state_dict(), 'roberta_bug_report_model.pt')\n",
    "    tokenizer.save_pretrained('roberta_bug_report_model')\n",
    "\n",
    "    global_model = model \n",
    "    global_tokenizer = tokenizer\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'bug_report.csv'\n",
    "bug_report.to_csv(file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
